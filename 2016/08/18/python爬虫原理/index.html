<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>ptython爬虫学习系列记录一 python爬虫原理 | DB</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">ptython爬虫学习系列记录一 python爬虫原理</h1><a id="logo" href="/.">DB</a><p class="description">我爱着温柔的夜</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/my/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">ptython爬虫学习系列记录一 python爬虫原理</h1><div class="post-meta">Aug 18, 2016<span> | </span><span class="category"><a href="/categories/python/">python</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/08/18/python爬虫原理/" href="/2016/08/18/python爬虫原理/#comments" class="ds-thread-count"></a><div class="post-content"><h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><p>任何事物都可以看做一个对象。以对象方式来看待一个项目，并做合理的功能区间拆分，有助于我们更好的理解与管理项目。</p>
<p>如果把爬虫看成一只真实存在的虫子，我们大体可以将之拆分为以下几个功能件：</p>
<ul>
<li>调度器：负责调度其他功能件一起协同完成任务</li>
<li><a href="#urlmanager">url管理器</a>:负责向下载器分发下载url，并将下载过的链接进行记录[id]</li>
<li><a href="#downloader">下载器</a>:负责下载目标网址</li>
<li><a href="#parser">解析器</a>:负责将下载下来的网页内容解析成我们需要的内容</li>
<li><a href="#saver">存储器</a>:负责将下载下来的内容存储到存储设备</li>
</ul>
<p>下面我们一个一个来分析各个功能件。</p>
<p><strong>注意</strong>：看代码，特别是调度器的代码，应该以“读伪代码”的方式来看。这样能跟着整个流程来走，不至于被其他“枝节”影响到对流程的理解。</p>
<h3 id="构件分析"><a href="#构件分析" class="headerlink" title="构件分析"></a>构件分析</h3><h4 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h4><p>兵马未动，代码现行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> url_manager</div><div class="line"><span class="keyword">import</span> html_downloader</div><div class="line"><span class="keyword">import</span> html_parser</div><div class="line"><span class="keyword">import</span> html_outputer</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderMain</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.urls = url_manager.UrlManager()	<span class="comment">#调入url管理器</span></div><div class="line">        self.downloader = html_downloader.HtmlDownloader(） <span class="comment">#调入html下载器</span></div><div class="line">        self.parser = html_parser.HtmlParser() <span class="comment">#调入html解析器</span></div><div class="line">        self.outputer = html_outputer.HtmlOutputer() <span class="comment">#调入存储器</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">craw</span><span class="params">(self, root_url)</span>:</span></div><div class="line">        count = <span class="number">1</span></div><div class="line">        self.urls.add_new_url(root_url)	<span class="comment">#初始化url管理器数据</span></div><div class="line">        <span class="keyword">while</span> self.urls.has_new_url():		<span class="comment">#只要url管理器里还有数据，循环不会终止</span></div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                new_url = self.urls.get_new_url() 	<span class="comment">#从url管理器中取出一个url资源</span></div><div class="line">                <span class="keyword">print</span> <span class="string">'craw %d :  %s'</span>  % (count,new_url) </div><div class="line">                html_cont = self.downloader.download(new_url) 	<span class="comment">#下载这个资源</span></div><div class="line">                new_urls,new_data = self.parser.parse(new_url,html_cont) 	<span class="comment">#解析资源</span></div><div class="line">                self.urls.add_new_urls(new_urls) 	<span class="comment">#将解析出来的新的url添加到url管理器中</span></div><div class="line">                self.outputer.collect_data(new_data) 	<span class="comment">#将解析出来的数据进行存储</span></div><div class="line">                <span class="keyword">if</span> count == <span class="number">500</span>: 	<span class="comment">#测试，输出500条数据后停止</span></div><div class="line">                    <span class="keyword">break</span>;</div><div class="line">                count = count + <span class="number">1</span></div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">print</span> <span class="string">'failed'</span></div><div class="line">        </div><div class="line">        self.outputer.output_html()</div><div class="line">        </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    root_url = <span class="string">"http://baike.baidu.com/view/21087.htm"</span></div><div class="line">    obj_spider = SpiderMain()</div><div class="line">    obj_spider.craw(root_url)</div></pre></td></tr></table></figure>
<p><strong>流程解析</strong>：</p>
<ol>
<li>向url管理器中添加初始化url。</li>
<li>url管理器向下载器分发未下载过的url。</li>
<li>下载器下载接收到的url。</li>
<li>解析器获取需要的内容，并将新获得的url添加到url管理器中。</li>
<li>通过存储器将内容存储起来。</li>
</ol>
<p>看完上面所述的调度器所控制的流程以及注释，下面我们一个一个看看各个组件的具体实现。<br><a name="urlmanager"></a></p>
<h4 id="url管理器"><a href="#url管理器" class="headerlink" title="url管理器"></a>url管理器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="string">'''</span></div><div class="line">Created on 2016年8月10日</div><div class="line">@author: ruanwenwu</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UrlManager</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.new_urls = set()</div><div class="line">        self.old_urls = set()</div><div class="line">    </div><div class="line">    <span class="comment">#向管理器中添加一条url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_url</span><span class="params">(self,url)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.new_urls <span class="keyword">and</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.old_urls:</div><div class="line">            self.new_urls.add(url)</div><div class="line">    </div><div class="line">    <span class="comment">#向管理器中添加多条url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_urls</span><span class="params">(self,urls)</span>:</span></div><div class="line">        <span class="keyword">if</span> urls <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> len(urls) == <span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">            self.add_new_url(url)</div><div class="line">    </div><div class="line">    <span class="comment">#判断管理器中是否还有未爬的url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self.new_urls) != <span class="number">0</span></div><div class="line">    </div><div class="line">    <span class="comment">#从管理器中取出一个url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        new_url = self.new_urls.pop()</div><div class="line">        self.old_urls.add(new_url)</div><div class="line">        <span class="keyword">return</span> new_url</div></pre></td></tr></table></figure>
<p>url管理器里有四个方法，具体说明请看注释。<br><a name="downloader"></a></p>
<h4 id="下载器"><a href="#下载器" class="headerlink" title="下载器"></a>下载器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlDownloader</span><span class="params">(object)</span>:</span></div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self,url)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        </div><div class="line">        response = urllib2.urlopen(url)</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> response.getcode() != <span class="number">200</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="keyword">return</span> response.read()</div></pre></td></tr></table></figure>
<p>下载器接收一个url作为参数，使用urllib2这个库进行下载，并返回下载的内容。<br><a name="parser"></a></p>
<h4 id="解析器"><a href="#解析器" class="headerlink" title="解析器"></a>解析器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urlparse</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlParser</span><span class="params">(object)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#解析器主要程序。获得数据内容和新的url资源</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self ,page_url, html_cont)</span>:</span></div><div class="line">        <span class="keyword">if</span> page_url <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> html_cont <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        </div><div class="line">        soup = BeautifulSoup(html_cont,<span class="string">"html.parser"</span>,from_encoding=<span class="string">"utf-8"</span>)</div><div class="line">        new_urls = self._get_new_urls(page_url, soup)</div><div class="line">        new_data = self._get_new_data(page_url, soup)</div><div class="line">        <span class="keyword">return</span> new_urls,new_data</div><div class="line">    </div><div class="line">    <span class="comment">#从html内容中获取新的url资源，并添加到url管理器</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_urls</span><span class="params">(self,page_url,soup)</span>:</span></div><div class="line">        new_urls = set()</div><div class="line">        links = soup.find_all(<span class="string">'a'</span>,href=re.compile(<span class="string">r"/view/\d+\.htm"</span>))</div><div class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</div><div class="line">            new_url = link[<span class="string">'href'</span>]</div><div class="line">            new_full_url = urlparse.urljoin(page_url,new_url)</div><div class="line">            new_urls.add(new_full_url)</div><div class="line">        <span class="keyword">return</span> new_urls</div><div class="line">    </div><div class="line">    <span class="comment">#从html内容中获得需要的数据，并返回</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_data</span><span class="params">(self,page_url,soup)</span>:</span></div><div class="line">        res_data = &#123;&#125;</div><div class="line">        res_data[<span class="string">'url'</span>] = page_url</div><div class="line">        title_node = soup.find(<span class="string">'dd'</span>, class_=<span class="string">"lemmaWgt-lemmaTitle-title"</span>).find(<span class="string">"h1"</span>)</div><div class="line">        res_data[<span class="string">'title'</span>] = title_node.get_text()</div><div class="line">        summary_node = soup.find(<span class="string">"div"</span> , class_=<span class="string">"lemma-summary"</span>)</div><div class="line">        res_data[<span class="string">'summary'</span>] = summary_node.get_text()</div><div class="line">        <span class="keyword">return</span> res_data</div></pre></td></tr></table></figure>
<p>url解析器接收从下载器中传递过来的html内容作为参数。使用BeautifulSoup这个库，和re这个库进行内容解析。三个方法的具体作用，请看注释。<br><a name="saver"></a></p>
<h4 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlOutputer</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.datas = []</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collect_data</span><span class="params">(self,data)</span>:</span></div><div class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        self.datas.append(data)</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_html</span><span class="params">(self)</span>:</span></div><div class="line">        fout = open(<span class="string">'output.html'</span> , <span class="string">'w'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;html&gt;'</span>)</div><div class="line">        fout.write(<span class="string">"&lt;meta charset='utf-8'/&gt;"</span>)</div><div class="line">        fout.write(<span class="string">'&lt;body&gt;'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;table border="1"&gt;'</span>)</div><div class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> self.datas:</div><div class="line">            fout.write(<span class="string">'&lt;tr&gt;'</span>)</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'url'</span>])</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'title'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'summary'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">'&lt;/tr&gt;'</span>)</div><div class="line">        fout.write(<span class="string">"&lt;/table&gt;"</span>)</div><div class="line">        fout.write(<span class="string">'&lt;/body&gt;'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;/html&gt;'</span>)</div><div class="line">        fout.close()</div></pre></td></tr></table></figure>
<p>上面的存储器采用的文件的方式进行的存储。当然也可以采用数据库。 </p>
<p>源码地址:<a href="https://github.com/ruanwenwu/basic-python-drawer" target="_blank" rel="external">https://github.com/ruanwenwu/basic-python-drawer</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2016/08/18/python爬虫原理/" data-id="cis45koay0002nk6rosxtlaq2" class="article-share-link">分享到</a><div class="tags"><a href="/tags/爬虫/">爬虫</a></div><div class="post-nav"><a href="/2016/08/14/搭建hexo并发布到github-pages/" class="next">Mac环境下搭建hexo并发布到Github Pages</a></div><div data-thread-key="2016/08/18/python爬虫原理/" data-title="ptython爬虫学习系列记录一 python爬虫原理" data-url="http://yoursite.com/2016/08/18/python爬虫原理/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2016/08/18/python爬虫原理/" data-title="ptython爬虫学习系列记录一 python爬虫原理" data-url="http://yoursite.com/2016/08/18/python爬虫原理/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/08/18/python爬虫原理/">ptython爬虫学习系列记录一 python爬虫原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/14/搭建hexo并发布到github-pages/">Mac环境下搭建hexo并发布到Github Pages</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">DB.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script>var duoshuoQuery = {short_name:'ruanwenwu'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>