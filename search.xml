<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[ptython爬虫学习系列记录一 python爬虫原理]]></title>
      <url>http://yoursite.com/2016/08/18/python%E7%88%AC%E8%99%AB%E5%8E%9F%E7%90%86/</url>
      <content type="html"><![CDATA[<h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><p>任何事物都可以看做一个对象。以对象方式来看待一个项目，并做合理的功能区间拆分，有助于我们更好的理解与管理项目。</p>
<p>如果把爬虫看成一只真实存在的虫子，我们大体可以将之拆分为以下几个功能件：</p>
<ul>
<li>调度器：负责调度其他功能件一起协同完成任务</li>
<li><a href="#urlmanager">url管理器</a>:负责向下载器分发下载url，并将下载过的链接进行记录[id]</li>
<li><a href="#downloader">下载器</a>:负责下载目标网址</li>
<li><a href="#parser">解析器</a>:负责将下载下来的网页内容解析成我们需要的内容</li>
<li><a href="#saver">存储器</a>:负责将下载下来的内容存储到存储设备</li>
</ul>
<p>下面我们一个一个来分析各个功能件。</p>
<p><strong>注意</strong>：看代码，特别是调度器的代码，应该以“读伪代码”的方式来看。这样能跟着整个流程来走，不至于被其他“枝节”影响到对流程的理解。</p>
<h3 id="构件分析"><a href="#构件分析" class="headerlink" title="构件分析"></a>构件分析</h3><h4 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h4><p>兵马未动，代码现行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> url_manager</div><div class="line"><span class="keyword">import</span> html_downloader</div><div class="line"><span class="keyword">import</span> html_parser</div><div class="line"><span class="keyword">import</span> html_outputer</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderMain</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.urls = url_manager.UrlManager()	<span class="comment">#调入url管理器</span></div><div class="line">        self.downloader = html_downloader.HtmlDownloader(） <span class="comment">#调入html下载器</span></div><div class="line">        self.parser = html_parser.HtmlParser() <span class="comment">#调入html解析器</span></div><div class="line">        self.outputer = html_outputer.HtmlOutputer() <span class="comment">#调入存储器</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">craw</span><span class="params">(self, root_url)</span>:</span></div><div class="line">        count = <span class="number">1</span></div><div class="line">        self.urls.add_new_url(root_url)	<span class="comment">#初始化url管理器数据</span></div><div class="line">        <span class="keyword">while</span> self.urls.has_new_url():		<span class="comment">#只要url管理器里还有数据，循环不会终止</span></div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                new_url = self.urls.get_new_url() 	<span class="comment">#从url管理器中取出一个url资源</span></div><div class="line">                <span class="keyword">print</span> <span class="string">'craw %d :  %s'</span>  % (count,new_url) </div><div class="line">                html_cont = self.downloader.download(new_url) 	<span class="comment">#下载这个资源</span></div><div class="line">                new_urls,new_data = self.parser.parse(new_url,html_cont) 	<span class="comment">#解析资源</span></div><div class="line">                self.urls.add_new_urls(new_urls) 	<span class="comment">#将解析出来的新的url添加到url管理器中</span></div><div class="line">                self.outputer.collect_data(new_data) 	<span class="comment">#将解析出来的数据进行存储</span></div><div class="line">                <span class="keyword">if</span> count == <span class="number">500</span>: 	<span class="comment">#测试，输出500条数据后停止</span></div><div class="line">                    <span class="keyword">break</span>;</div><div class="line">                count = count + <span class="number">1</span></div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">print</span> <span class="string">'failed'</span></div><div class="line">        </div><div class="line">        self.outputer.output_html()</div><div class="line">        </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    root_url = <span class="string">"http://baike.baidu.com/view/21087.htm"</span></div><div class="line">    obj_spider = SpiderMain()</div><div class="line">    obj_spider.craw(root_url)</div></pre></td></tr></table></figure>
<p><strong>流程解析</strong>：</p>
<ol>
<li>向url管理器中添加初始化url。</li>
<li>url管理器向下载器分发未下载过的url。</li>
<li>下载器下载接收到的url。</li>
<li>解析器获取需要的内容，并将新获得的url添加到url管理器中。</li>
<li>通过存储器将内容存储起来。</li>
</ol>
<p>看完上面所述的调度器所控制的流程以及注释，下面我们一个一个看看各个组件的具体实现。<br><a name="urlmanager"></a></p>
<h4 id="url管理器"><a href="#url管理器" class="headerlink" title="url管理器"></a>url管理器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="string">'''</span></div><div class="line">Created on 2016年8月10日</div><div class="line">@author: ruanwenwu</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UrlManager</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.new_urls = set()</div><div class="line">        self.old_urls = set()</div><div class="line">    </div><div class="line">    <span class="comment">#向管理器中添加一条url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_url</span><span class="params">(self,url)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.new_urls <span class="keyword">and</span> url <span class="keyword">not</span> <span class="keyword">in</span> self.old_urls:</div><div class="line">            self.new_urls.add(url)</div><div class="line">    </div><div class="line">    <span class="comment">#向管理器中添加多条url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_new_urls</span><span class="params">(self,urls)</span>:</span></div><div class="line">        <span class="keyword">if</span> urls <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> len(urls) == <span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</div><div class="line">            self.add_new_url(url)</div><div class="line">    </div><div class="line">    <span class="comment">#判断管理器中是否还有未爬的url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self.new_urls) != <span class="number">0</span></div><div class="line">    </div><div class="line">    <span class="comment">#从管理器中取出一个url</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_new_url</span><span class="params">(self)</span>:</span></div><div class="line">        new_url = self.new_urls.pop()</div><div class="line">        self.old_urls.add(new_url)</div><div class="line">        <span class="keyword">return</span> new_url</div></pre></td></tr></table></figure>
<p>url管理器里有四个方法，具体说明请看注释。<br><a name="downloader"></a></p>
<h4 id="下载器"><a href="#下载器" class="headerlink" title="下载器"></a>下载器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlDownloader</span><span class="params">(object)</span>:</span></div><div class="line">    </div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self,url)</span>:</span></div><div class="line">        <span class="keyword">if</span> url <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        </div><div class="line">        response = urllib2.urlopen(url)</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> response.getcode() != <span class="number">200</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="keyword">return</span> response.read()</div></pre></td></tr></table></figure>
<p>下载器接收一个url作为参数，使用urllib2这个库进行下载，并返回下载的内容。<br><a name="parser"></a></p>
<h4 id="解析器"><a href="#解析器" class="headerlink" title="解析器"></a>解析器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="keyword">import</span> urlparse</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlParser</span><span class="params">(object)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#解析器主要程序。获得数据内容和新的url资源</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self ,page_url, html_cont)</span>:</span></div><div class="line">        <span class="keyword">if</span> page_url <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> html_cont <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        </div><div class="line">        soup = BeautifulSoup(html_cont,<span class="string">"html.parser"</span>,from_encoding=<span class="string">"utf-8"</span>)</div><div class="line">        new_urls = self._get_new_urls(page_url, soup)</div><div class="line">        new_data = self._get_new_data(page_url, soup)</div><div class="line">        <span class="keyword">return</span> new_urls,new_data</div><div class="line">    </div><div class="line">    <span class="comment">#从html内容中获取新的url资源，并添加到url管理器</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_urls</span><span class="params">(self,page_url,soup)</span>:</span></div><div class="line">        new_urls = set()</div><div class="line">        links = soup.find_all(<span class="string">'a'</span>,href=re.compile(<span class="string">r"/view/\d+\.htm"</span>))</div><div class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</div><div class="line">            new_url = link[<span class="string">'href'</span>]</div><div class="line">            new_full_url = urlparse.urljoin(page_url,new_url)</div><div class="line">            new_urls.add(new_full_url)</div><div class="line">        <span class="keyword">return</span> new_urls</div><div class="line">    </div><div class="line">    <span class="comment">#从html内容中获得需要的数据，并返回</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_new_data</span><span class="params">(self,page_url,soup)</span>:</span></div><div class="line">        res_data = &#123;&#125;</div><div class="line">        res_data[<span class="string">'url'</span>] = page_url</div><div class="line">        title_node = soup.find(<span class="string">'dd'</span>, class_=<span class="string">"lemmaWgt-lemmaTitle-title"</span>).find(<span class="string">"h1"</span>)</div><div class="line">        res_data[<span class="string">'title'</span>] = title_node.get_text()</div><div class="line">        summary_node = soup.find(<span class="string">"div"</span> , class_=<span class="string">"lemma-summary"</span>)</div><div class="line">        res_data[<span class="string">'summary'</span>] = summary_node.get_text()</div><div class="line">        <span class="keyword">return</span> res_data</div></pre></td></tr></table></figure>
<p>url解析器接收从下载器中传递过来的html内容作为参数。使用BeautifulSoup这个库，和re这个库进行内容解析。三个方法的具体作用，请看注释。<br><a name="saver"></a></p>
<h4 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HtmlOutputer</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.datas = []</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collect_data</span><span class="params">(self,data)</span>:</span></div><div class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line">        self.datas.append(data)</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_html</span><span class="params">(self)</span>:</span></div><div class="line">        fout = open(<span class="string">'output.html'</span> , <span class="string">'w'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;html&gt;'</span>)</div><div class="line">        fout.write(<span class="string">"&lt;meta charset='utf-8'/&gt;"</span>)</div><div class="line">        fout.write(<span class="string">'&lt;body&gt;'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;table border="1"&gt;'</span>)</div><div class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> self.datas:</div><div class="line">            fout.write(<span class="string">'&lt;tr&gt;'</span>)</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'url'</span>])</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'title'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">"&lt;td&gt;%s&lt;/td&gt;"</span> % data[<span class="string">'summary'</span>].encode(<span class="string">'utf-8'</span>))</div><div class="line">            fout.write(<span class="string">'&lt;/tr&gt;'</span>)</div><div class="line">        fout.write(<span class="string">"&lt;/table&gt;"</span>)</div><div class="line">        fout.write(<span class="string">'&lt;/body&gt;'</span>)</div><div class="line">        fout.write(<span class="string">'&lt;/html&gt;'</span>)</div><div class="line">        fout.close()</div></pre></td></tr></table></figure>
<p>上面的存储器采用的文件的方式进行的存储。当然也可以采用数据库。 </p>
<p>源码地址:<a href="https://github.com/ruanwenwu/basic-python-drawer" target="_blank" rel="external">https://github.com/ruanwenwu/basic-python-drawer</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Mac环境下搭建hexo并发布到Github Pages]]></title>
      <url>http://yoursite.com/2016/08/14/%E6%90%AD%E5%BB%BAhexo%E5%B9%B6%E5%8F%91%E5%B8%83%E5%88%B0github-pages/</url>
      <content type="html"><![CDATA[<p>首先，最好切换到root用户,否则每次都要sudu，特别麻烦。</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>sudo -i</div></pre></td></tr></table></figure>
<h3 id="安装开发依赖环境git和node-js"><a href="#安装开发依赖环境git和node-js" class="headerlink" title="安装开发依赖环境git和node.js"></a>安装开发依赖环境git和node.js</h3><p>这两个软件的安装都比较容易。其中mac的话，最好安装Xcode，集成git，能少爬一点坑。</p>
<p>安装好git和node.js后就可以安装hexo了</p>
<p>进入到hexo的<a href="https://hexo.io/docs/" target="_blank" rel="external">官网文档页面</a>，按照文档说明一步一步来。</p>
<h3 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h3><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ npm install -g hexo-<span class="keyword">cli</span></div></pre></td></tr></table></figure>
<p>安装博客到folder这个目录,如果不跟这个目录的话，就是默认到当前目录<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>hexo init &lt;folder&gt;</div><div class="line"><span class="variable">$ </span>cd &lt;folder&gt;</div><div class="line"><span class="variable">$ </span>npm install</div></pre></td></tr></table></figure></p>
<p>到这里你就可以运行</p>
<figure class="highlight axapta"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo <span class="keyword">server</span></div></pre></td></tr></table></figure>
<p>来启动本地hexo服务了。在浏览器里输入<a href="http://localhost:4000" target="_blank" rel="external">http://localhost:4000</a>就能看到hellow world这篇文章了。</p>
<p>最后，介绍我现在用的这个我自己非常喜欢的主题：<a href="https://www.haomwei.com/technology/maupassant-hexo.html" target="_blank" rel="external">大道至简</a></p>
]]></content>
    </entry>
    
  
  
</search>
